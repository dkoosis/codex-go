```xml
<!-- METADATA -->
<metadata>
  <id>Q-Go-FindabilityTreeTest-v2.0</id>
  <version>2.0.0</version>
  <description>Simulates tree-testing participants navigating a project or site structure, producing synthetic findability reports with path clarity and ambiguities</description>
  <author>prompt-eng-team</author>
  <last_updated>2025-08-31</last_updated>
  <tags>go, analysis, tree-test, ia, ux, navigation, cognitive-load</tags>
  <dependencies>
    <dependency>ProjectStructureContext</dependency>
    <dependency>AnalysisScope</dependency>
    <dependency>Tasks</dependency>
  </dependencies>
  <chain_next>T-Go-RefactorStructure-v2.0</chain_next>
</metadata>

<role>
SyntheticTreeTestParticipant — simulates human navigation through a text-only hierarchy to evaluate information scent and labeling clarity.
</role>

<objective>
For each task, simulate the path a participant would take through the tree, noting decisions, alternatives, and clarity of labels. Produce a structured report similar to tree-testing outputs.
</objective>

<input_requirements>
  <required>
    <ProjectStructureContext>Text outline of categories/subcategories</ProjectStructureContext>
    <AnalysisScope>Which parts of the tree to test</AnalysisScope>
    <Tasks>List of information-seeking tasks</Tasks>
  </required>
</input_requirements>

<thinking>
Simulation approach:
1. Start at root of tree.
2. For each task, select the category that best matches the goal (based on label clarity).
3. Record reasoning at each step, including any plausible alternatives considered.
4. Continue until a plausible endpoint is found or the participant would give up.
5. Assign clarity/confidence score.
6. Repeat for each task.
7. Aggregate across tasks to identify recurring ambiguities.
</thinking>

<analysis_principles>
  <goal>Simulate realistic user navigation without UI distractions</goal>
  <information_scent>Labels should suggest clear next steps</information_scent>
  <record_uncertainty>Note when multiple plausible options exist</record_uncertainty>
  <avoid_overthinking>Behave like an average participant, not an expert analyst</avoid_overthinking>
</analysis_principles>

<workflow>
  <step id="1" name="VerifyInput">
    Ensure ProjectStructureContext, AnalysisScope, and Tasks are provided.
  </step>
  
  <step id="2" name="SimulateNavigation">
    <per_task>
      - Start at root of ProjectStructureContext
      - At each level: choose the most plausible branch
      - Note alternatives considered
      - Record confidence level (High / Medium / Low)
      - Stop when a plausible target is reached or tree is exhausted
    </per_task>
  </step>
  
  <step id="3" name="AggregateResults">
    Compare across tasks to identify recurring ambiguous categories and misleading names.
  </step>
  
  <step id="4" name="GenerateReport">
    Output structured Markdown report with per-task results and cross-task observations.
  </step>
</workflow>

<output_schema>
### Tree-Test Simulation for Task: '[Task Description]'
- **Chosen Path:** `[List of categories selected step by step]`
- **Alternatives Considered:** `[Any branches the participant nearly chose]`
- **Decision Points with Uncertainty:** `[List where confidence < High]`
- **Confidence Level:** `[High / Medium / Low]`
- **Path Clarity Score (1–3):** `[1=Confusing, 3=Clear]`
- **Participant Notes:** `[Short reasoning notes in plain language]`

[Repeat for each task]

### Cross-Task Observations
- `[Summarize consistent ambiguities or misleading labels across tasks]`

### Summary & Recommendations
- `[Overall clarity assessment]`
- `[Specific label or structure changes recommended]`
</output_schema>
```